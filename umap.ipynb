{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.datasets as tdatasets\n",
    "import umap.umap_ as umap\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import seaborn as sns\n",
    "\n",
    "from fastai import datasets,layers\n",
    "from fastai.vision import ImageList\n",
    "from fastai.basic_train import Learner\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.callback import Callback\n",
    "from ipdb import set_trace\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from functools import partial\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "import torchvision.datasets as tdatasets\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import utils\n",
    "utils.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NZ=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', rc={'figure.figsize':(10,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_check_exists', 'download', 'processed_folder', 'raw_folder', 'root', 'target_transform', 'test_file', 'train', 'train_data', 'train_labels', 'training_file', 'transform', 'urls']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist=tdatasets.MNIST(root='~/unsupervised_object_learning/data/',train=True,download=True)\n",
    "print(dir(mnist))\n",
    "mnist_dataset = utils.TransformDataset(mnist.train_data,[to_float_tensor,add_colour_dimension],device='cuda',x_only=True)\n",
    "\n",
    "mnist_data = mnist.train_data.view(60000,-1)\n",
    "kjkllh\n",
    "mnist_data = to_float_tensor(mnist_data)\n",
    "mnist_data.shape,mnist_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis/anaconda3/envs/unsupervised_object_learning/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../anaconda3/envs/unsupervised_object_learning/lib/python3.7/site-packages/umap/rp_tree.py\", line 135:\n",
      "@numba.njit(fastmath=True, nogil=True, parallel=True)\n",
      "def euclidean_random_projection_split(data, indices, rng_state):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/louis/anaconda3/envs/unsupervised_object_learning/lib/python3.7/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../anaconda3/envs/unsupervised_object_learning/lib/python3.7/site-packages/umap/utils.py\", line 409:\n",
      "@numba.njit(parallel=True)\n",
      "def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "^\n",
      "\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/home/louis/anaconda3/envs/unsupervised_object_learning/lib/python3.7/site-packages/numba/typed_passes.py:271: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../anaconda3/envs/unsupervised_object_learning/lib/python3.7/site-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "umap_embeddings = umap.UMAP(random_state=42).fit_transform(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor.ndim = property(lambda x: len(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-72986f6e9dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumap_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmnist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/unsupervised_object_learning/utils.py\u001b[0m in \u001b[0;36mscatter_clusters\u001b[0;34m(embeddings, labels)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'purple'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'brown'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnumpyify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnumpyify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/unsupervised_object_learning/utils.py\u001b[0m in \u001b[0;36mnumpyify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "utils.scatter_clusters(umap_embeddings,mnist_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['r','k','y','g','b','m','purple','brown','c','orange']\n",
    "\n",
    "for i in range(10):\n",
    "    plt.scatter(umap_embeddings[mnist_labels.numpy()==i,0], umap_embeddings[mnist_labels.numpy()==i,1], s=0.1, c=palette[i], label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz,ngf,nc):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reslike_block(nfs,sz):\n",
    "    return nn.Sequential(\n",
    "        *[layers.conv_layer(nfs[i],nfs[i+1],stride=2 if i==0 else 1,norm_type='batchnorm_2d',leaky=0.3,padding=1)\n",
    "         for i in range(len(nfs)-1)], nn.AdaptiveAvgPool2d(sz))\n",
    "\n",
    "def get_enc_dec():\n",
    "    block1 = get_reslike_block([1,4,8,16,32],sz=7)\n",
    "    block2 = get_reslike_block([32,64,128,256,NZ],sz=1)\n",
    "    enc = nn.Sequential(block1,block2)\n",
    "    dec = Generator(nz=NZ,ngf=32,nc=1)    \n",
    "    return enc,dec\n",
    "\n",
    "def get_enc_dec_mu_var():\n",
    "    block1 = get_reslike_block([1,4,8,16,32],sz=7)\n",
    "    block2 = get_reslike_block([32,64,128,256],sz=1)\n",
    "    mu_net = nn.Linear(256,NZ)\n",
    "    var_net = nn.Linear(256,NZ)\n",
    "    enc = nn.Sequential(block1,block2)\n",
    "    dec = Generator(nz=NZ,ngf=32,nc=1)    \n",
    "    return enc,dec,mu_net,var_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc,dec = get_enc_dec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE():\n",
    "    def __init__(self,enc,dec,dataset,opt,loss_func): \n",
    "        self.enc,self.dec,self.dataset,self.loss_func = enc,dec,dataset,loss_func\n",
    "        self.opt = opt(params = [{'params':enc.parameters()},{'params':dec.parameters()}])\n",
    "        self.writer = SummaryWriter()\n",
    "        \n",
    "    def one_batch(self,xb):\n",
    "        latent = self.enc(xb)\n",
    "        pred = self.dec(latent)\n",
    "        return self.loss_func(pred,xb),pred\n",
    "      \n",
    "    @property\n",
    "    def data(self): \n",
    "        dl = data.DataLoader(self.dataset,batch_sampler=data.BatchSampler(data.SequentialSampler(mnist_dataset),len(self.dataset),drop_last=False))\n",
    "        return next(iter(dl))\n",
    "    @property\n",
    "    def latents(self): return self.enc(self.data)\n",
    "    \n",
    "    def train(self,epochs,bs):\n",
    "        dl = data.DataLoader(self.dataset,batch_sampler=data.BatchSampler(data.RandomSampler(mnist_dataset),bs,drop_last=True))\n",
    "        for epoch in range(epochs):\n",
    "            for i, xb in enumerate(dl): \n",
    "                loss,pred = self.one_batch(xb)\n",
    "                self.writer.add_scalar('ae/rloss',loss,i)\n",
    "                loss.backward(); self.opt.step(); self.opt.zero_grad()\n",
    "            self.writer.add_images('Test_batch',pred,epoch)\n",
    "            \n",
    "    def check_ae_images(self,num_rows=5):\n",
    "        inimgs = self.dataset[:num_rows*4]\n",
    "        x = self.enc(inimgs)\n",
    "        outimgs = self.dec(x)\n",
    "        print(outimgs.shape)\n",
    "        _, axes = plt.subplots(num_rows,4,figsize=(7,7))\n",
    "        for i in range(num_rows):\n",
    "            axes[i,0].imshow(inimgs[i,0])\n",
    "            axes[i,1].imshow(outimgs[i,0])\n",
    "            axes[i,2].imshow(inimgs[i+num_rows,0])\n",
    "            axes[i,3].imshow(outimgs[i+num_rows,0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AE(enc,dec,mnist_dataset,opt=torch.optim.Adam,loss_func=nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.train(epochs=9,bs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.check_ae_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_latents = ae.latents[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_umap = umap.UMAP(random_state=42).fit_transform(ae_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_umap = umap.UMAP(min_dist=0, n_neighbors=30,random_state=42).fit_transform(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=500).fit_predict(ae_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels2 = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=500).fit_predict(clusterable_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels3 = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=500).fit_predict(ae_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels4 = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=500).fit_predict(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = hdbscan_labels>=0\n",
    "hdbscan_labels[clustered]\n",
    "clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(ae_umap[hdbscan_labels4==i,0], ae_umap[hdbscan_labels4==i,1], s=0.1, c=palette[i], label=i)\n",
    "plt.scatter(ae_umap[~clustered,0],ae_umap[~clustered,1],c=[0.5,0.5,0.5],s=0.1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(ae_umap[hdbscan_labels2==i,0], ae_umap[hdbscan_labels2==i,1], s=0.1, c=palette[i], label=i)\n",
    "plt.scatter(ae_umap[~clustered,0],ae_umap[~clustered,1],c=[0.5,0.5,0.5],s=0.1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mnist_labels.numpy()[clustered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(hdbscan_labels[clustered],mnist_labels.numpy()[clustered]),adjusted_mutual_info_score(hdbscan_labels[clustered],mnist_labels.numpy()[clustered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['r','k','y','g','b','m','purple','brown','c','orange']\n",
    "\n",
    "for i in range(10):\n",
    "    plt.scatter(ae_umap[mnist_labels.numpy()==i,0], ae_umap[mnist_labels.numpy()==i,1], s=0.1, c=palette[i], label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist(mnist_vecs):\n",
    "    umapped = umap.UMAP(random_state=42).fit_transform(mnist_vecs)\n",
    "    palette = ['r','k','y','g','b','m','purple','brown','c','orange']\n",
    "    labels = mnist_labels.numpy()\n",
    "    for i in range(10):\n",
    "        plt.scatter(umapped[mnist_labels==i,0], umapped[mnist_labels==i,1], s=0.1, c=palette[i], label=i)\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
